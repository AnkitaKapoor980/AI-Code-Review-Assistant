from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Optional
import uvicorn
import openai
import json
from datetime import datetime
import hashlib
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
import torch
import asyncio
import aiohttp

app = FastAPI(
    title="Real AI Code Review Assistant",
    description="ðŸš€ True AI-powered code analysis with real-time LLM suggestions",
    version="2.0.0"
)

# Configuration - Add your API keys
OPENAI_API_KEY = "your-openai-key"  # For GPT-4
HUGGING_FACE_TOKEN = "your-hf-token"  # For Hugging Face models

class CodeReviewRequest(BaseModel):
    code: str
    language: str = "python"
    context: Optional[str] = None
    ai_model: str = "gpt-4"  # gpt-4, claude, codellama, starcoder

class AICodeIssue(BaseModel):
    line: int
    severity: str
    category: str
    message: str
    ai_suggestion: str  # Generated by AI
    ai_explanation: str  # Why this is an issue
    fixed_code: Optional[str]  # AI-generated fix
    confidence: float  # AI confidence 0-1

class AIReviewResponse(BaseModel):
    review_id: str
    timestamp: str
    overall_score: float
    issues: List[AICodeIssue]
    ai_summary: str  # AI-generated summary
    ai_improvements: List[str]  # AI-generated suggestions
    refactored_code: Optional[str]  # AI-improved version

# Initialize AI models
code_llm = None
openai.api_key = OPENAI_API_KEY

def get_code_llm():
    """Initialize local code LLM (CodeLlama or StarCoder)"""
    global code_llm
    if code_llm is None:
        # Using CodeLlama for code understanding
        code_llm = pipeline(
            "text-generation",
            model="codellama/CodeLlama-7b-Instruct-hf",
            torch_dtype=torch.float16,
            device_map="auto"
        )
    return code_llm

async def analyze_with_gpt4(code: str, language: str) -> Dict:
    """Use GPT-4 for real-time code analysis"""
    
    system_prompt = f"""You are an expert {language} code reviewer. Analyze the provided code and return a JSON response with:
1. Issues found (line number, severity, category, detailed explanation, specific suggestion)
2. Overall quality score (0-100)
3. Detailed improvement recommendations
4. Refactored version of the code if improvements are needed

Focus on:
- Security vulnerabilities
- Performance optimizations  
- Code maintainability
- Best practices
- Potential bugs

Be specific and actionable in your suggestions."""

    user_prompt = f"""Please review this {language} code:

```{language}
{code}
```

Return response as JSON with this structure:
{{
    "overall_score": 85,
    "issues": [
        {{
            "line": 5,
            "severity": "high",
            "category": "security",
            "message": "Specific issue description",
            "suggestion": "Specific fix recommendation",
            "explanation": "Why this is problematic",
            "confidence": 0.95
        }}
    ],
    "summary": "AI-generated summary of code quality",
    "improvements": ["specific improvement 1", "specific improvement 2"],
    "refactored_code": "improved version if needed"
}}"""

    try:
        response = await openai.ChatCompletion.acreate(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.1,
            max_tokens=2000
        )
        
        ai_response = response.choices[0].message.content
        # Parse JSON response from GPT-4
        return json.loads(ai_response)
        
    except Exception as e:
        print(f"GPT-4 analysis failed: {e}")
        return None

async def analyze_with_claude(code: str, language: str) -> Dict:
    """Use Claude API for code analysis"""
    
    # Claude API implementation
    # Similar structure to GPT-4 but using Anthropic's API
    
    prompt = f"""Analyze this {language} code for issues and improvements:

{code}

Provide detailed, actionable feedback in JSON format."""
    
    # Implementation would use Anthropic's API
    # This is a placeholder - you'd need to implement the actual API call
    
    return None

async def analyze_with_local_llm(code: str, language: str) -> Dict:
    """Use local CodeLlama for analysis"""
    
    llm = get_code_llm()
    
    prompt = f"""<s>[INST] You are a code reviewer. Analyze this {language} code and identify issues:

{code}

Provide specific suggestions for improvement. [/INST]"""

    try:
        response = llm(prompt, max_length=1000, temperature=0.1)
        ai_text = response[0]['generated_text']
        
        # Parse the AI response and structure it
        # This would need custom parsing logic
        
        return {
            "ai_analysis": ai_text,
            "model_used": "CodeLlama-7B"
        }
        
    except Exception as e:
        print(f"Local LLM analysis failed: {e}")
        return None

async def get_ai_code_fix(issue_code: str, issue_description: str, language: str) -> str:
    """Generate AI-powered code fix"""
    
    prompt = f"""Fix this {language} code issue:

ISSUE: {issue_description}

CODE:
```{language}
{issue_code}
```

Provide only the corrected code:"""

    try:
        response = await openai.ChatCompletion.acreate(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,
            max_tokens=500
        )
        
        return response.choices[0].message.content.strip()
        
    except:
        return None

@app.post("/ai-review", response_model=AIReviewResponse)
async def ai_code_review(request: CodeReviewRequest):
    """ðŸ¤– Get real AI-powered code review with LLM-generated suggestions"""
    
    try:
        review_id = hashlib.md5(f"{request.code}{datetime.now()}".encode()).hexdigest()[:8]
        
        # Choose AI model based on request
        ai_result = None
        
        if request.ai_model == "gpt-4":
            ai_result = await analyze_with_gpt4(request.code, request.language)
        elif request.ai_model == "claude":
            ai_result = await analyze_with_claude(request.code, request.language)
        elif request.ai_model == "local":
            ai_result = await analyze_with_local_llm(request.code, request.language)
        
        if not ai_result:
            raise HTTPException(status_code=500, detail="AI analysis failed")
        
        # Convert AI response to our format
        ai_issues = []
        for issue_data in ai_result.get("issues", []):
            # Generate AI fix for each issue
            code_lines = request.code.split('\n')
            issue_line = issue_data.get("line", 1)
            issue_context = '\n'.join(code_lines[max(0, issue_line-2):issue_line+1])
            
            ai_fix = await get_ai_code_fix(
                issue_context, 
                issue_data.get("message", ""), 
                request.language
            )
            
            ai_issues.append(AICodeIssue(
                line=issue_data.get("line", 1),
                severity=issue_data.get("severity", "medium"),
                category=issue_data.get("category", "general"),
                message=issue_data.get("message", "AI detected an issue"),
                ai_suggestion=issue_data.get("suggestion", "AI suggestion unavailable"),
                ai_explanation=issue_data.get("explanation", "Analysis pending"),
                fixed_code=ai_fix,
                confidence=issue_data.get("confidence", 0.8)
            ))
        
        return AIReviewResponse(
            review_id=review_id,
            timestamp=datetime.now().isoformat(),
            overall_score=ai_result.get("overall_score", 75),
            issues=ai_issues,
            ai_summary=ai_result.get("summary", "AI analysis completed"),
            ai_improvements=ai_result.get("improvements", []),
            refactored_code=ai_result.get("refactored_code")
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AI review failed: {str(e)}")

@app.post("/hybrid-review")
async def hybrid_review(request: CodeReviewRequest):
    """ðŸ”¥ Combine rule-based + AI analysis for best results"""
    
    # Run both rule-based (fast) and AI analysis (thorough) in parallel
    rule_task = asyncio.create_task(rule_based_analysis(request.code, request.language))
    ai_task = asyncio.create_task(analyze_with_gpt4(request.code, request.language))
    
    rule_result, ai_result = await asyncio.gather(rule_task, ai_task)
    
    # Merge results intelligently
    merged_issues = merge_analysis_results(rule_result, ai_result)
    
    return {
        "hybrid_analysis": True,
        "rule_based_issues": len(rule_result.get("issues", [])),
        "ai_issues": len(ai_result.get("issues", [])),
        "merged_issues": merged_issues,
        "confidence": "high"
    }

async def rule_based_analysis(code: str, language: str) -> Dict:
    """Fast rule-based analysis (from previous implementation)"""
    # Your existing pattern-matching logic here
    return {"issues": [], "score": 80}

def merge_analysis_results(rule_result: Dict, ai_result: Dict) -> List:
    """Intelligently merge rule-based and AI results"""
    # Combine and deduplicate issues
    # Prioritize AI insights where available
    # Fall back to rules for speed
    
    merged = []
    # Implementation logic here
    return merged

@app.get("/ai-models")
async def available_models():
    """List available AI models for code review"""
    return {
        "models": [
            {
                "name": "gpt-4",
                "description": "OpenAI GPT-4 - Highest quality analysis",
                "speed": "slow",
                "cost": "high",
                "accuracy": "excellent"
            },
            {
                "name": "claude",
                "description": "Anthropic Claude - Great for code understanding",
                "speed": "medium",
                "cost": "medium", 
                "accuracy": "excellent"
            },
            {
                "name": "local",
                "description": "CodeLlama 7B - Fast local processing",
                "speed": "fast",
                "cost": "free",
                "accuracy": "good"
            }
        ]
    }

if __name__ == "__main__":
    print("ðŸ¤– Starting REAL AI Code Review Assistant...")
    print("ðŸ“Š Supports: GPT-4, Claude, CodeLlama")
    print("ðŸš€ Real-time AI suggestions enabled!")
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)
